{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import null_space\n",
    "from IPython.display import clear_output\n",
    "from sklearn.linear_model import LassoLars\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pd.read_csv(\"../Data/data.csv\").drop(['Unnamed: 0'], axis = 1).to_numpy()\n",
    "#y = pd.read_csv(\"../Data/labels.csv\").drop(['Unnamed: 0'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_proto = X[1:101, 1:201]\n",
    "#y_proto = y[1:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = pd.read_csv(\"../Data/BreastTissue.csv\").drop(['Case #'],axis = 1).drop(['Class'],axis=1).to_numpy()\n",
    "y_small = pd.read_csv(\"../Data/BreastTissue.csv\").drop(['Case #'],axis = 1)['Class'].to_numpy()\n",
    "\n",
    "y_small = preprocessing.LabelEncoder().fit_transform(y_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(array):\n",
    "    \"\"\"Calculate the Gini coefficient of a numpy array.\"\"\"\n",
    "    # based on bottom eq:\n",
    "    # http://www.statsdirect.com/help/generatedimages/equations/equation154.svg\n",
    "    # from:\n",
    "    # http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm\n",
    "    # All values are treated equally, arrays must be 1d:\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0:\n",
    "        # Values cannot be negative:\n",
    "        array -= np.amin(array)\n",
    "    # Values cannot be 0:\n",
    "    array += 0.0000001\n",
    "    # Values must be sorted:\n",
    "    array = np.sort(array)\n",
    "    # Index per array element:\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    # Number of array elements:\n",
    "    n = array.shape[0]\n",
    "    # Gini coefficient:\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAObject:\n",
    "    def __init__(self, PCs, X, label):\n",
    "        assert len(PCs) == min(X.shape[0],X.shape[1]), \"Need all the principal components!\"\n",
    "        self.pcs = PCs\n",
    "        self.X = StandardScaler().fit_transform(X)\n",
    "        self.cov = np.cov(self.X.T)\n",
    "        self.label = label\n",
    "        \n",
    "        self._calcExpVar()\n",
    "        self._calcNonZeroLoads()\n",
    "        self._calcGini()\n",
    "        self._calcWgtGini()    \n",
    "    \n",
    "    def _calcExpVar(self):\n",
    "        tot_var = np.sum(np.diag(self.cov))\n",
    "        self.ev = np.diag(self.pcs @ np.cov(self.X.T) @ self.pcs.T)/np.linalg.norm(self.pcs, axis = 1)**2\n",
    "        self.ev[np.isnan(self.ev)] = 0\n",
    "        self.pev = [ev/tot_var for ev in self.ev]\n",
    "        self.cev = np.cumsum(np.flip(np.sort(self.pev)))\n",
    "        \n",
    "    def _calcNonZeroLoads(self):\n",
    "        self.nonZeroLoads = [np.count_nonzero(pc) for pc in self.pcs]\n",
    "        \n",
    "    def _calcGini(self):\n",
    "        self.gini = [gini(i) for i in self.pcs]\n",
    "        \n",
    "    def _calcWgtGini(self):\n",
    "        self.wgtGini = np.sum([gini * pev for gini, pev in zip(self.gini, self.pev)])\n",
    "        \n",
    "    def plotNonZeroLoadtoPEV(self):\n",
    "        plt.plot(self.nonZeroLoads, self.pev, label=self.label)\n",
    "        plt.xlabel('Number of non-zero loadings')\n",
    "        plt.xscale('log')\n",
    "        plt.ylabel('Percentage of explained variance (PEV)')\n",
    "        plt.legend()\n",
    "        plt.title('Percentage of explained variance (PEV) vs non-zero loadings')\n",
    "        \n",
    "    def plotCEV(self):\n",
    "        x = np.arange(len(self.pcs))\n",
    "        \n",
    "        plt.plot(x, np.sort(self.cev), label = self.label)\n",
    "        plt.xlabel('Number of component')\n",
    "        plt.ylabel('Cumulative explained variance (CEV)')\n",
    "        plt.legend()\n",
    "        plt.title('Cumulative explained variance (CEV)')\n",
    "        \n",
    "    def plotSparsitytoEV(self,k): #k is which PC you want to plot\n",
    "        plt.scatter(self.gini[k], self.ev[k], label = self.label)\n",
    "        plt.xlabel('Sparsity of PC '+str(k+1))\n",
    "        plt.ylabel('Explained Variance of PC '+str(k+1))\n",
    "        plt.xlim((0,1))\n",
    "        plt.legend()\n",
    "        plt.title('Sparsity of PC versus Expained Variance of PC '+str(k+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_PCA(X, k = \"all\"): \n",
    "    \"\"\"\n",
    "    function takes an n x p feature matrix\n",
    "    returns two arrays:\n",
    "    - array with percentage of explained variance in first k principal directions (k_comp x 1)\n",
    "    - array with principal directions (k_comp x p)\n",
    "    \"\"\"\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    if k == \"all\": k = min(X.shape[0],X.shape[1])\n",
    "    pca = PCA(n_components = k)\n",
    "    pca.fit(X)\n",
    "    PEVs = pca.explained_variance_ratio_\n",
    "    prin_comp = pca.components_\n",
    "    EVs = pca.explained_variance_\n",
    "    \n",
    "    return PEVs, prin_comp, EVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_PCA(X, thresh = 1e-1, k = \"all\"):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - X: n x p feature matrix\n",
    "    - thresh: float representing this non-zero cutoff\n",
    "    - k: integer for number of principal directions wanted\n",
    "    returns one array:\n",
    "    - array with principal components in its columns (k x p)\n",
    "    \"\"\"\n",
    "    if k == \"all\": k = min(X.shape[0],X.shape[1])\n",
    "\n",
    "    pcs = reg_PCA(X)[1]\n",
    "    pcs = (np.abs(pcs) >= thresh).astype(int) * pcs\n",
    "    \n",
    "    return pcs[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonZeroLoad_PCA(X,j, k = \"max\"):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - X: n x p feature matrix\n",
    "    - j: integer for number of non-zero loadings,\n",
    "    - k: integer for number of principal directions wanted\n",
    "    returns three arrays:\n",
    "    - array with percentages of explained variance in first k principal directions (k x 1)\n",
    "    - array with principal directions (k x p)\n",
    "    - array with explained variances\n",
    "    \"\"\"   \n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    if k == \"all\": k = min(X.shape[0],X.shape[1])\n",
    "    \n",
    "    PCA_PEV, PCA_PC, PCA_EV = reg_PCA(X,min(X.shape[0],X.shape[1]))\n",
    "    \n",
    "    total_var = sum(PCA_EV)\n",
    "    \n",
    "    thresh_PCA_PC = np.empty((0,PCA_PC.shape[1]))\n",
    "    thresh_PCA_PEV = []\n",
    "    thresh_PCA_EV = []\n",
    "    \n",
    "    PCA_PC_sorted = np.sort(np.absolute(PCA_PC), axis = 1)\n",
    "    for m in range(k):\n",
    "        thresh = PCA_PC_sorted[m][-j]\n",
    "        thresh_PC = (np.absolute(PCA_PC[m]) >= thresh).astype(int)*PCA_PC[m]\n",
    "        thresh_PCA_PC = np.vstack((thresh_PCA_PC, thresh_PC))\n",
    "    \n",
    "    return thresh_PCA_PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpTrans(r, s, k, X_scaled):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - Two directions r and s to transform\n",
    "    - An integer k that restricts the possible directions\n",
    "    - The scaled data matrix X\n",
    "    returns two vectors and three floats\n",
    "    - Two new directions r and s\n",
    "    - Two floats representing the variances explained by the new directions r and s\n",
    "    - One float representing the covariance of the new directions r and s\n",
    "    \"\"\"\n",
    "    # Calculate the covariance matrix for the two directions\n",
    "    cov = np.vstack((r,s)) @ np.cov(X_scaled.T) @ np.vstack((r,s)).T\n",
    "    v_old_r, v_old_s, v_old_rs = cov[0,0], cov[1,1], cov[0,1]\n",
    "    \n",
    "    # Get a list of all possible betas\n",
    "    poss_beta1 = [i/2**k for i in range(-2**k, 2**k+1, 1)]\n",
    "    poss_beta2 = [2**k/i for i in range(-2**k, 2**k+1, 1) if i != 0]\n",
    "    poss_beta = np.sort(list(set(poss_beta1 + poss_beta2)))\n",
    "    \n",
    "    # Calculate the norms of the two directions\n",
    "    l2_r, l2_s = np.linalg.norm(r)**2, np.linalg.norm(s)**2\n",
    "    \n",
    "    # Find the beta that maximizes the variance in the normalized\n",
    "    # direction of the first new principal component\n",
    "    v_r, v_s, v_rs = cov[0,0], cov[1,1], cov[0,1]\n",
    "    a = l2_s*v_rs\n",
    "    b = np.sqrt(l2_r*l2_s)*(v_r - v_s)\n",
    "    c = l2_r*v_rs\n",
    "    discr = b**2 - 4*a*c\n",
    "    beta_star = (-b+np.sqrt(discr))/(2*a)\n",
    "    \n",
    "    # Select beta from possible values that's closest to the optimal value\n",
    "    beta_star = min(list(poss_beta), \n",
    "                    key = lambda x:abs(x-beta_star))\n",
    "    \n",
    "    # Calculate the two new directions\n",
    "    if abs(beta_star) <= 1:\n",
    "        r_new = 2**k*r + 2**k*beta_star*s\n",
    "        s_new = 2**k*beta_star*l2_s*r - 2**k*l2_r*s\n",
    "    else:\n",
    "        r_new = 2**k*r/beta_star + 2**k*s\n",
    "        s_new = 2**k*l2_s*r - 2**k*l2_r*s/beta_star\n",
    "    \n",
    "    # Calculate variances and covariance of the new directions\n",
    "    P = np.array([[1, l2_s*beta_star],[beta_star, -l2_r]])\n",
    "    cov_new = P.T @ cov @ P\n",
    "    v_r, v_s, v_rs = cov_new[0,0], cov_new[1,1], cov_new[0,1]\n",
    "    \n",
    "    return r_new, s_new, v_r, v_s, v_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcPairFinder(cov, cache):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - A covariance matrix\n",
    "    - A cache containing the indices of excluded pcs\n",
    "    returns two integers:\n",
    "    - i_r: the index of the first principal component\n",
    "    - i_s: the index of the second principal component\n",
    "    \"\"\"\n",
    "    # Turn covariance matrix into a sparse lower triangular matrix\n",
    "    grid = np.tril(cov, k = -1)\n",
    "    vrs = np.diag(cov)\n",
    "    # Flatten the grid and sort from largest cov to smallest cov\n",
    "    srt = np.sort(np.ravel(grid), kind = 'heapsort')\n",
    "    lst = list(np.flip(np.trim_zeros(srt)))\n",
    "    mask = False\n",
    "    \n",
    "    # Find the pair of pcs that are not already in the cache and hav\n",
    "    # the highest covariance in the grid\n",
    "    while not np.any(mask):\n",
    "        covar = lst.pop(0)\n",
    "        index = np.argwhere(grid == covar)\n",
    "        mask = np.ravel(np.invert(np.any(np.isin(index, cache), axis = 1, keepdims = True)))\n",
    "\n",
    "    # Unpack the indices make sure that the variance of r is larger than the variance of s\n",
    "    index = index[mask,:][0]\n",
    "    i_r = index[np.argmax([vrs[i] for i in index])]\n",
    "    i_s = index[np.argmin([vrs[i] for i in index])]\n",
    "    return i_r, i_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_PCA(X, k, iters = 1):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - An unscaled data matrix X\n",
    "    - An integer k that restricts the possible directions\n",
    "    - An integer indicating the number of iterations\n",
    "    returns one array:\n",
    "    - array with principal components in its columns (k x p)\n",
    "    \"\"\"\n",
    "    # Retrieve the principal components and their covariance matrix\n",
    "    n_obs, n_feats = X.shape\n",
    "    q = np.identity(n_obs)\n",
    "    for _ in range(n_feats//n_obs):\n",
    "        q = np.hstack((q,np.identity(n_obs)))\n",
    "    pcs = q[:n_obs,:n_feats]\n",
    "    \n",
    "    cov = np.cov(X.T)\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Setup up globals for loop\n",
    "    cov_pc = pcs @ cov @ pcs.T\n",
    "    cache = []\n",
    "    \n",
    "    for _ in range(iters):\n",
    "        while len(cache) <= len(pcs) - 2:\n",
    "            clear_output(wait = True)\n",
    "            print(\"Working on principal component \", len(cache) + 2,\"/\",len(pcs))\n",
    "            \n",
    "            # Find set of principal components to transform\n",
    "            i_r, i_s = pcPairFinder(cov_pc, cache)\n",
    "            r, s = pcs[i_r], pcs[i_s]\n",
    "            cache += [i_r, i_s]\n",
    "            \n",
    "            # Transform the pair of components\n",
    "            print(\"Determining new directions...\")\n",
    "            r_new, s_new, v_r, v_s, v_rs = SimpTrans(r, s, k, X_scaled)\n",
    "\n",
    "            # Update the principal components\n",
    "            pcs[i_r] = r_new\n",
    "            pcs[i_s] = s_new\n",
    "            \n",
    "            # Update the grid matrix\n",
    "            cov_pc[i_s, i_r], cov_pc[i_r, i_s] = v_rs, v_rs\n",
    "    \n",
    "    return pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scotlass_pen(x, gamma):\n",
    "    '''\n",
    "    regularization penalty function for SCoTLASS\n",
    "    \n",
    "    function takes \n",
    "    - x: float\n",
    "    - gamma: float\n",
    "    \n",
    "    function returns \n",
    "    - penalty value: float\n",
    "    '''\n",
    "    return (0.5 * x) * (1 + np.tanh(gamma*x))\n",
    "\n",
    "def scotlass_obj(sigma, v, reg_param, gamma):\n",
    "    '''\n",
    "    objective function for SCoTLASS\n",
    "    \n",
    "    function takes\n",
    "    - sigma: p x p covariance matrix\n",
    "    - v: p x 1 vector\n",
    "    - reg_param: regularization parameter (positive float)\n",
    "    - gamma: float\n",
    "    \n",
    "    function returns\n",
    "    - objective function value at v (p x 1 vector)\n",
    "    '''\n",
    "    varimax = (0.5*v.T) @ sigma @ v\n",
    "    argpen = v.T @ np.tanh(1000*v)-reg_param\n",
    "    penalty = gamma * scotlass_pen(argpen, gamma)\n",
    "    return np.array(varimax - penalty).flatten()\n",
    "\n",
    "def scotlass_grad(sigma, v, reg_param, gamma):\n",
    "    '''\n",
    "    gradient of objective function for SCoTLASS\n",
    "    \n",
    "    function takes\n",
    "    - sigma: p x p covariance matrix\n",
    "    - v: p x 1 vector\n",
    "    - reg_param: regularization parameter (positive float)\n",
    "    - gamma: float\n",
    "    \n",
    "    function returns\n",
    "    - gradient of objective function at v\n",
    "    '''\n",
    "    # Setup of parameters\n",
    "    mu = 1000\n",
    "    \n",
    "    # Calculate floats\n",
    "    y = (v.T @ np.tanh(gamma*v))-reg_param\n",
    "    q = 1 + np.tanh(gamma*y) + gamma*np.cosh(gamma*y)**(-2)*y\n",
    "    \n",
    "    # Calculate vectors\n",
    "    z = np.tanh(gamma*v) + gamma * (np.diag(np.ravel(np.cosh(gamma*v)**(-2))) @ v)\n",
    "    \n",
    "    return (sigma @ v) - 0.5*mu*q*z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scotlassGradAsc(sigma, V, reg_param , x0 = 'default', \n",
    "                    alpha = 10**-3, max_iter = 20000, crit = 1e-1000):\n",
    "    '''\n",
    "    function takes\n",
    "    - sigma: p x p covariance matrix\n",
    "    - reg_param: regularization parameter (positive float); Default = sqrt(p)\n",
    "    - x0: Initial value of the vector\n",
    "    - alpha: Step size of gradient descent (<1 for convergence)\n",
    "    - max_iters: max number of steps (positive integer)\n",
    "    - crit: critical stopping value for the gradient descent algorithm\n",
    "    \n",
    "    function returns\n",
    "    - v: first sparse principal direction (array of length p)\n",
    "    - variance of data along v\n",
    "    '''\n",
    "    # Configure the parameters\n",
    "    iters, delta, gamma = 1, 1, 1000\n",
    "    num_obs, num_feat = sigma.shape\n",
    "    \n",
    "    # Configure the regularization parameter\n",
    "#     reg_error = '''\n",
    "#     The regularization parameter needs to be smaller than \n",
    "#     the square root of the number of features in the dataset.\n",
    "#     '''\n",
    "#     if reg_param == 'default': reg_param = np.sqrt(num_feat)\n",
    "#     else: assert reg_param <= np.sqrt(num_feat), reg_error\n",
    "    \n",
    "    # Initialize the algorithm\n",
    "    if x0 == 'default': x0 = np.ones(shape = (num_feat,1))\n",
    "    elif x0 == 'random': x0 = np.random.rand(num_feat,1)\n",
    "    else: pass\n",
    "    v = x0/np.linalg.norm(x0)\n",
    "    \n",
    "    # Projected gradient descent\n",
    "    # Stopping criteria:\n",
    "    # (1) Maximum iterations reached\n",
    "    # (2) Change in objective function negligible\n",
    "    while iters < max_iter and delta > crit:\n",
    "        \n",
    "        # Update the vector\n",
    "        v_new = v + alpha*scotlass_grad(sigma, v, reg_param, gamma)\n",
    "        \n",
    "        # Project loading vector back onto feasible set \n",
    "        # (vectors of l2 norm of 1 that are orthogonal to all other pcs)\n",
    "        v_proj = V @ v_new\n",
    "        v_proj = v_proj/(np.linalg.norm(v_proj))\n",
    "        \n",
    "        # Use the projected loading vector to retrieve the value of the\n",
    "        # objective function\n",
    "        old_obj = scotlass_obj(sigma, v, reg_param, gamma)[0]\n",
    "        updated_obj = scotlass_obj(sigma, v_proj, reg_param, gamma)[0]\n",
    "\n",
    "        # Calculate the difference in value of the objective function\n",
    "        delta = [updated_obj - old_obj][0]\n",
    "        #print(delta)\n",
    "        # Update vector and number of iterations\n",
    "        v, iters = v_proj, iters + 1\n",
    "    \n",
    "    # return loadings array v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCoTLASS(X, reg_param, x0 = 'default', alpha = 10**-3,\n",
    "             max_iter = 20000, crit = 1e-1000):\n",
    "    '''\n",
    "    function takes\n",
    "    - X: n x p dataset\n",
    "    - reg_param: regularization parameter (positive float); Default = sqrt(p)\n",
    "    - x0: Initial value of the vector\n",
    "    - alpha: Step size of gradient descent (<1 for convergence)\n",
    "    - max_iters: max number of steps (positive integer)\n",
    "    - crit: critical stopping value for the gradient descent algorithm\n",
    "    \n",
    "    function returns\n",
    "    - array with principal components in its columns (n x p)\n",
    "    '''\n",
    "    # Standardize the dataset\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    sigma = np.cov(X.T)\n",
    "    num_feat = X.shape[1]\n",
    "    num_samp = X.shape[0]\n",
    "    \n",
    "    # Initialize an array for principal components\n",
    "    pcs = np.zeros(shape = (min(X.shape[0],X.shape[1]),X.shape[1]))\n",
    "    \n",
    "    # Initialize projection vector V\n",
    "    V = np.identity(num_feat)\n",
    "    \n",
    "    for _ in range(len(pcs)):\n",
    "        # Find the best principal component\n",
    "        pc = scotlassGradAsc(sigma, V, reg_param, x0, alpha, max_iter, crit)\n",
    "        pcs[_] = pc.T\n",
    "        \n",
    "        # Project the covariance matrix and x0 \n",
    "        # on the orthogonal complement of previous pcs\n",
    "        V = null_space(pcs[:_+1]) @ null_space(pcs[:_+1]).T\n",
    "        sigma = V @ sigma\n",
    "        x0 = V @ np.ones(shape = (num_feat,1))\n",
    "    return pcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $B\\in \\mathbb{R}^{p\\times m}$:\n",
    "$$\n",
    "Varimax(B) = \\frac{1}{p^2}\\sum_{k=1}^m\\left[\\underbrace{m\\sum_{j=1}^p b_{jk}^4}_{P} - \\underbrace{\\left(\\sum_{j=1}^p b_{jk}^2\\right)^2}_{Q}\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varimax(x):\n",
    "    '''\n",
    "    varimax penalty function\n",
    "    \n",
    "    function takes 1 x p vector\n",
    "    \n",
    "    function returns float\n",
    "    '''\n",
    "    #     p, m = B[None,:].shape\n",
    "    #     P = m*np.sum(np.power(B, 4), axis = 0)\n",
    "    #     Q = np.power(np.sum(np.power(B, 2), axis = 0), 2)\n",
    "    #     return 1/p**2 * np.sum(P - Q)\n",
    "    \n",
    "    p = len(x)\n",
    "    varimax = np.sum(np.power(x, 4))\n",
    "    varimax -= (x.T @ x)[0]**2\n",
    "    varimax = varimax/(p**2)\n",
    "    \n",
    "    return varimax\n",
    "\n",
    "def varimax_grad(x):\n",
    "    '''\n",
    "    varimax penalty function gradient\n",
    "    \n",
    "    function takes 1 x p vector\n",
    "    \n",
    "    function returns 1 x p varimax gradient vector'''\n",
    "    p = len(x)\n",
    "    grad = 4*(np.power(x, 3) - (x.T @ x)* x)/(p**2)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def scot_obj(sigma, v, reg_param):\n",
    "    '''\n",
    "    SCoT objective function\n",
    "    \n",
    "    function takes\n",
    "    - sigma: p x p covariance matrix\n",
    "    - v: 1 x p vector\n",
    "    - reg_param: varimax regularization parameter (positive float)\n",
    "    \n",
    "    function returns float\n",
    "    '''\n",
    "    obj = v.T @ sigma @ v + (reg_param*varimax(v))[0]\n",
    "\n",
    "    return obj\n",
    "\n",
    "def scot_obj_grad(sigma, v, reg_param):\n",
    "    '''\n",
    "    SCoT objective function gradient\n",
    "    \n",
    "    function takes\n",
    "    - sigma: p x p covariance matrix\n",
    "    - v: 1 x p vector\n",
    "    - reg_param: varimax regularization parameter (positive float)\n",
    "    \n",
    "    function returns 1 x p gradient vector\n",
    "    '''\n",
    "    \n",
    "    p = len(v)\n",
    "    grad = np.array((sigma @ v)) + reg_param*varimax_grad(v)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scotGradAsc(sigma, V, reg_param, x0 = 'default', \n",
    "                    alpha = 10**-3, max_iter = 20000, crit = 1e-1000):\n",
    "    '''\n",
    "    function takes\n",
    "    - sigma: p x p covariance matrix\n",
    "    - reg_param: regularization parameter (positive float); Default = sqrt(p)\n",
    "    - x0: Initial value of the vector\n",
    "    - alpha: Step size of gradient descent (<1 for convergence)\n",
    "    - max_iters: max number of steps (positive integer)\n",
    "    - crit: critical stopping value for the gradient descent algorithm\n",
    "    \n",
    "    function returns\n",
    "    - v: first sparse principal direction (array of length p)\n",
    "    - variance of data along v\n",
    "    '''\n",
    "    # Configure the parameters\n",
    "    iters, delta, gamma = 1, 1, 1000\n",
    "    num_obs, num_feat = sigma.shape\n",
    "    \n",
    "    # Initialize the algorithm\n",
    "    if x0 == 'default': x0 = np.ones(shape = (num_feat,1))\n",
    "    elif x0 == 'random': x0 = np.random.rand(num_feat,1)\n",
    "    else: pass\n",
    "    v = x0/np.linalg.norm(x0)\n",
    "    \n",
    "    # Projected gradient descent\n",
    "    # Stopping criteria:\n",
    "    # (1) Maximum iterations reached\n",
    "    # (2) Change in objective function negligible\n",
    "    while iters < max_iter and delta > crit:\n",
    "        \n",
    "        # Update the vector\n",
    "        v_new = v + alpha*scot_obj_grad(sigma, v, reg_param)\n",
    "        \n",
    "        # Project loading vector back onto feasible set \n",
    "        # (vectors of l2 norm of 1 that are orthogonal to all other pcs)\n",
    "        v_proj = V @ v_new\n",
    "        v_proj = v_proj/(np.linalg.norm(v_proj))\n",
    "        \n",
    "        # Use the projected loading vector to retrieve the value of the\n",
    "        # objective function\n",
    "        old_obj = scot_obj(sigma, v, reg_param)[0]\n",
    "        updated_obj = scot_obj(sigma, v_proj, reg_param)[0]\n",
    "\n",
    "        # Calculate the difference in value of the objective function\n",
    "        delta = [updated_obj - old_obj][0]\n",
    "        \n",
    "        # Update vector and number of iterations\n",
    "        v, iters = v_proj, iters + 1\n",
    "    \n",
    "    # return loadings array v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SCoT(X, reg_param, x0 = 'default', alpha = 10**-3,\n",
    "             max_iter = 20000\n",
    "         \n",
    "         , crit = 1e-1000):\n",
    "    '''\n",
    "    function takes\n",
    "    - X: n x p dataset\n",
    "    - reg_param: regularization parameter (positive float)\n",
    "    - x0: Initial value of the vector\n",
    "    - alpha: Step size of gradient descent (<1 for convergence)\n",
    "    - max_iters: max number of steps (positive integer)\n",
    "    - crit: critical stopping value for the gradient descent algorithm\n",
    "    function returns\n",
    "    \n",
    "    - array with principal components in its columns (n x p)\n",
    "    '''\n",
    "    # Standardize the dataset\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    sigma = np.cov(X.T)\n",
    "    num_feat = sigma.shape[0]\n",
    "    \n",
    "    # Initialize an array for principal components\n",
    "    pcs = np.zeros(shape = (min(X.shape[0],X.shape[1]),X.shape[1]))\n",
    "    \n",
    "    # Initial vector for gradient descent\n",
    "    if x0 == 'default': x0 = np.ones(shape = (num_feat,1))\n",
    "    elif x0 == 'random': x0 = np.random.rand(num_feat,1)\n",
    "    else: pass\n",
    "    v = x0/np.linalg.norm(x0)\n",
    "    \n",
    "    V = np.identity(X.shape[1])\n",
    "    \n",
    "    for _ in range(len(pcs)):\n",
    "        # Find the best principal component\n",
    "        pc = scotGradAsc(sigma, V, reg_param, x0, alpha, max_iter, crit)\n",
    "        pcs[_] = pc.T\n",
    "        \n",
    "        # Project the covariance matrix and x0 \n",
    "        # on the orthogonal complement of previous pcs\n",
    "        V = null_space(pcs[:_+1]) @ null_space(pcs[:_+1]).T\n",
    "        sigma = V @ sigma\n",
    "        x0 = V @ np.ones(shape = (num_feat,1))\n",
    "        x0 = x0/np.linalg.norm(x0)\n",
    "        \n",
    "    return pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVDProblem(B, X):\n",
    "    '''\n",
    "    function takes\n",
    "    - X: n x p dataset\n",
    "    - B: p x n matrix\n",
    "    \n",
    "    function returns\n",
    "    - A: p x n matrix\n",
    "    '''\n",
    "    U, D, V = np.linalg.svd(X.T @ X @ B)\n",
    "\n",
    "    return U @ V.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SPCA(X, reg_param, reg_param1, max_iter = 1000, crit = 1e-10):\n",
    "    '''\n",
    "    function takes\n",
    "    - X: n x p dataset\n",
    "    - reg_param: regularization parameter (positive float)\n",
    "    - x0: Initial value of the vector\n",
    "    - alpha: Step size of gradient descent (<1 for convergence)\n",
    "    - max_iters: max number of steps (positive integer)\n",
    "    - crit: critical stopping value for the gradient descent algorithm\n",
    "    \n",
    "    function returns\n",
    "    - array with principal components in its columns (n x p)\n",
    "    '''\n",
    "    # (1) Let A start at V[,1:k] the loadings of the first \n",
    "    # k ordinary principal components\n",
    "    A = reg_PCA(X)[1].T\n",
    "    B = np.zeros_like(A)\n",
    "    \n",
    "    \n",
    "    # Normalize the dataset\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    iters, delta, A_old = 1, 1, A\n",
    "    while iters < max_iter and delta > crit:\n",
    "       \n",
    "        # (2) Given a fixed A = [alpha_1, ..., alpha_k], solve the elastic\n",
    "        # net problem for j = 1, 2, ..., k\n",
    "        for i in range(len(A)):\n",
    "            \n",
    "            B[i] = LARS_EN(X @ A[:,i].reshape(-1,1), # Target variable\n",
    "                           X,                        # Data\n",
    "                           reg_param,                # l2-norm reg param\n",
    "                           reg_param1)               # l1-norm reg param\n",
    "        \n",
    "        # (3) For a fixed B = [beta_1, ..., beta_k], compute the SVD of \n",
    "        # X^TXB = UDV^T then update A = UV^T\n",
    "        A = SVDProblem(B.T, X)\n",
    "\n",
    "        # (4) Repeat steps (2) and (3) until convergence\n",
    "        #iters, delta, A_old = iters + 1, np.linalg.norm(A - A_old), A\n",
    "        iters, delta, A_old = iters + 1, np.linalg.norm(A - A_old), A\n",
    "        #print(f\"{iters} delta: {delta}\")\n",
    "    \n",
    "    # (5) Normalize the altered principal components\n",
    "    \n",
    "    return (A/np.linalg.norm(A, axis = 1)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 (B given A):\n",
    "$$\n",
    "\\hat{\\beta}_j = argmin_{\\beta_j} \\|Y_j - X\\beta_j\\|^2 + \\lambda\\|\\beta_j\\|^2 + \\lambda_{1,j}\\|\\beta_j\\|_1\n",
    "$$\n",
    "with $Y_j = X\\alpha_j$. We can rewrite this as\n",
    "$$\n",
    "\\hat{\\beta}^* = argmin_{\\beta^*} \\|Y^*_j - X^*\\beta^*\\|^2 + \\gamma\\|\\beta^*\\|_1\n",
    "$$\n",
    "with\n",
    "$$\n",
    "X^* = (1 + \\lambda)^{-1/2}\\begin{pmatrix}X\\\\\\sqrt{\\lambda I}\\end{pmatrix}\\in\\mathbb{R}^{(n+p)\\times p},\\qquad Y^* = \\begin{pmatrix}Y\\\\0\\end{pmatrix}\\in\\mathbb{R}^{n+p}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\gamma = \\frac{\\lambda_{1,j}}{\\sqrt{1+\\lambda}}\n",
    "$$\n",
    "From $\\beta^*$ we can find $\\hat{\\beta_j}$:\n",
    "$$\n",
    "\\hat{\\beta}=\\frac{1}{\\sqrt{1+\\lambda}}\\hat{\\beta}^*\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LARS_EN(Y, X, reg_param, reg_param1):\n",
    "    '''\n",
    "    function takes\n",
    "    - Y: p x 1 target variable\n",
    "    - X: n x p dataset\n",
    "    - reg_param: regularization parameter for l2-norm\n",
    "    - reg_param1: regularization parameter for l1-norm\n",
    "    \n",
    "    function returns\n",
    "    - beta: 1 x p vector with coefficients\n",
    "    '''\n",
    "    # Find the number of features\n",
    "    p = X.shape[1]\n",
    "    \n",
    "    # Create the artificial dataset for the naïve elastic net\n",
    "    X = np.power(1 + reg_param, -0.5) * np.vstack((X, np.sqrt(reg_param)*np.identity(p)))\n",
    "    Y = np.vstack((Y, np.zeros(shape = (p,1))))\n",
    "    gamma = reg_param1/np.sqrt(1 + reg_param)\n",
    "    \n",
    "    # Use the LARS (Efron 2004) algorithm to solve this lasso regression\n",
    "\n",
    "    lasso = LassoLars(alpha = gamma,\n",
    "                      fit_intercept = False,\n",
    "                      normalize = False,\n",
    "                      max_iter = 1000)\n",
    "    lasso.fit(X, Y)\n",
    "    \n",
    "    # Transform the found coefficients in the elastic net coefficients\n",
    "    beta = lasso.coef_/np.sqrt(1 + reg_param)\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38400649, -0.04438884,  0.09614038,  0.39705166,  0.35724004,\n",
       "         0.35359053,  0.39120075,  0.3608388 ,  0.38442982],\n",
       "       [-0.26534435,  0.75633324,  0.45549857,  0.02027549,  0.18010834,\n",
       "         0.24987842,  0.02195838,  0.0308506 , -0.2309766 ],\n",
       "       [-0.0995539 ,  0.29743094, -0.72295351,  0.26337124,  0.11868007,\n",
       "         0.00492335, -0.28122204,  0.42629751, -0.18620705],\n",
       "       [ 0.00646859,  0.1086915 , -0.4388029 , -0.36360193,  0.09781064,\n",
       "         0.62134007,  0.12837804, -0.47895946,  0.14790701],\n",
       "       [-0.29540487, -0.40167609,  0.04182519, -0.07841317,  0.79943887,\n",
       "        -0.02668558, -0.03380898, -0.05193293, -0.31597405],\n",
       "       [-0.41850149, -0.38372671,  0.15304412,  0.34001755, -0.33981961,\n",
       "         0.58548304, -0.24858548,  0.10614826, -0.085123  ],\n",
       "       [-0.46034432, -0.01582688, -0.20101779,  0.15182335, -0.18110696,\n",
       "        -0.15763569,  0.80385734, -0.01104491, -0.14288728],\n",
       "       [-0.10999924, -0.09043144,  0.04928993, -0.70383938, -0.08903486,\n",
       "         0.13567496,  0.10360325,  0.66564948,  0.04177543],\n",
       "       [-0.53455992,  0.09323331, -0.00766997,  0.01293654,  0.14485112,\n",
       "        -0.19921739, -0.17622429, -0.02315513,  0.78298562]])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_SPCA = PCAObject(SPCA(X_small, 1000, 2), X_small, \"SPCA\")\n",
    "reg_SPCA.pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.38744945, -0.04731079,  0.09353183,  0.39524554,  0.35163773,\n",
       "         0.35494151,  0.392272  ,  0.35798091,  0.38860924],\n",
       "       [-0.23954935,  0.66474199,  0.58567756, -0.05815884,  0.1670238 ,\n",
       "         0.27590649,  0.09826335, -0.09249779, -0.17916661],\n",
       "       [-0.22465384,  0.32695184, -0.47590882,  0.30911394,  0.28635994,\n",
       "        -0.01713069, -0.30561631,  0.49053609, -0.32290873],\n",
       "       [-0.13166554, -0.09277402, -0.44397307, -0.34000333,  0.476911  ,\n",
       "         0.48963972,  0.11323685, -0.42483434, -0.02906642],\n",
       "       [-0.25699858, -0.56871173,  0.41988891,  0.05908075,  0.53416903,\n",
       "        -0.20900507, -0.04148647,  0.08627042, -0.30420073],\n",
       "       [ 0.08100396, -0.19005279,  0.21591021, -0.07677492, -0.10563185,\n",
       "         0.53471086, -0.75044398,  0.13900602,  0.15888378],\n",
       "       [-0.38788206, -0.28239743, -0.03402799,  0.28426849, -0.48857613,\n",
       "         0.46491037,  0.33677124,  0.08990898, -0.33389511],\n",
       "       [-0.00237137,  0.03270856, -0.00683975,  0.7340915 ,  0.05906012,\n",
       "        -0.04077149, -0.22788832, -0.63213616,  0.05751333],\n",
       "       [-0.70825549,  0.00200142, -0.02244293,  0.01268819,  0.01784579,\n",
       "        -0.10221951,  0.00279709,  0.08797125,  0.69223653]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_SPCA.pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import SparsePCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spca = SparsePCA(n_components = 9, alpha = 1, ridge_alpha = 0.01)\n",
    "spca.fit(X_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_SPCA = PCAObject(spca.components_, X_small, \"SPCA - sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spca.components_ @ spca.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47607547,  0.24502511, -0.0139027 , -0.39579235, -0.26477845,\n",
       "        -0.02702382, -0.40288098, -0.30300955, -0.48114882],\n",
       "       [ 0.00710131,  0.2059377 , -0.00108811, -0.01445868,  0.01075305,\n",
       "         0.96205094, -0.03310469,  0.17211526, -0.0308509 ],\n",
       "       [-0.07056861,  0.48274403, -0.00762917, -0.18638801, -0.08659911,\n",
       "        -0.12160368,  0.7759842 ,  0.19892212, -0.25133888],\n",
       "       [-0.66123   , -0.41391381,  0.00138595,  0.00500728, -0.03924775,\n",
       "        -0.01466652,  0.04344299,  0.62180387,  0.03377007],\n",
       "       [-0.11108761,  0.54227447, -0.00879724, -0.21619714, -0.10228169,\n",
       "        -0.14184239, -0.25819295,  0.21429921,  0.70965541],\n",
       "       [-0.12508672,  0.40301061, -0.00684177,  0.83020355, -0.08270219,\n",
       "        -0.11242323, -0.20064339,  0.14702921, -0.22648845],\n",
       "       [-0.00260274,  0.01644458,  0.99973869, -0.00639192, -0.00298125,\n",
       "        -0.00417517, -0.007672  ,  0.00671904, -0.00861187],\n",
       "       [ 0.53063397,  0.0263768 , -0.01135849, -0.25028792, -0.07707936,\n",
       "        -0.14638038, -0.33611122,  0.61875702, -0.36298673],\n",
       "       [-0.14673226,  0.18905189, -0.00383845, -0.09853809,  0.94735719,\n",
       "        -0.06724769, -0.11225524,  0.04363894, -0.12841747]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_SPCA_home = PCAObject(SPCA(X_small, 0.01, 1.5), X_small, \"SPCA - home\")\n",
    "reg_SPCA_home.pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_reg = PCAObject(reg_PCA(X_small)[1], X_small, \"Regular\")\n",
    "reg_scotlass_1pt5= PCAObject(SCoTLASS(X_small,1.5,alpha = 10**-6, max_iter=100000), X_small, \"SCoTLASS 1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_SPCA_home.pcs @ reg_SPCA_home.pcs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weighted Gini SPCA: \", reg_SPCA.wgtGini)\n",
    "print(\"Weighted Gini Regular PCA: \", reg_reg.wgtGini)\n",
    "print(\"Weighted Gini SCoTLASS: \", reg_scotlass_1pt5.wgtGini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spca = SparsePCA(n_components = 9, alpha = 1.5, ridge_alpha = 0)\n",
    "spca.fit(X_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_SCoTLASS = PCAObject(spca.components_, X_small, \"SCoTLASS - sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(reg_scotlass_1pt5.pcs, axis = 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_scotlass_1pt5= PCAObject(SCoTLASS(X_small,3,alpha = 10**-6, max_iter=100000), X_small, \"SCoTLASS 1.5\")\n",
    "reg_scotlass_1pt5.pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_SPCA.pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_SPCA.plotCEV()\n",
    "reg_SCoTLASS.plotCEV()\n",
    "reg_SPCA_home.plotCEV()\n",
    "reg_reg.plotCEV()\n",
    "reg_scotlass_1pt5.plotCEV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reg_thresh = PCAObject(threshold_PCA(X_small), X_small, \"Thresh\")\n",
    "\n",
    "reg_reg = PCAObject(reg_PCA(X_small)[1], X_small, \"Regular\")\n",
    "\n",
    "reg_scot_100 = PCAObject(SCoT(X_small, 100, alpha = 10**-3), X_small, \"SCoT 100\")\n",
    "reg_scot_250 = PCAObject(SCoT(X_small, 250, alpha = 10**-3), X_small, \"SCoT 250\")\n",
    "reg_scot_500 = PCAObject(SCoT(X_small, 500, alpha = 10**-3), X_small, \"SCoT 500\")\n",
    "reg_scot_600 = PCAObject(SCoT(X_small, 600, alpha = 10**-3), X_small, \"SCoT 600\")\n",
    "reg_scot_750 = PCAObject(SCoT(X_small, 750, alpha = 10**-3), X_small, \"SCoT 750\")\n",
    "reg_scot_1000 = PCAObject(SCoT(X_small, 1000, alpha = 10**-3), X_small, \"SCoT 1000\")\n",
    "reg_scot_5000 = PCAObject(SCoT(X_small, 5000, alpha = 10**-3), X_small, \"SCoT 5000\")\n",
    "\n",
    "reg_scotlass_1 = PCAObject(SCoTLASS(X_small,1,alpha = 10**-6, max_iter = 500000), X_small, \"SCoTLASS 1\")\n",
    "reg_scotlass_1pt3 = PCAObject(SCoTLASS(X_small,1.3,alpha = 1.5*10**-6, max_iter = 500000), X_small, \"SCoTLASS 1.3\")\n",
    "reg_scotlass_1pt5= PCAObject(SCoTLASS(X_small,1.5,alpha = 2*10**-6, max_iter=500000), X_small, \"SCoTLASS 1.5\")\n",
    "reg_scotlass_1pt6= PCAObject(SCoTLASS(X_small,1.6,alpha = 2*10**-6, max_iter=500000), X_small, \"SCoTLASS 1.6\")\n",
    "reg_scotlass_2 = PCAObject(SCoTLASS(X_small,2,alpha = 2*10**-6, max_iter=1000000), X_small, \"SCoTLASS 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reg_thresh.plotCEV()\n",
    "reg_reg.plotCEV()\n",
    "reg_scot_100.plotCEV()\n",
    "reg_scot_500.plotCEV()\n",
    "reg_scot_750.plotCEV()\n",
    "reg_scot_1000.plotCEV()\n",
    "#reg_scotlass_2.plotCEV()\n",
    "#reg_scotlass_1pt6.plotCEV()\n",
    "#reg_scotlass_1pt5.plotCEV()\n",
    "#reg_scotlass_1.plotCEV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_reg.calcExpVar()\n",
    "reg_scot_100.calcExpVar()\n",
    "reg_scot_500.calcExpVar()\n",
    "reg_scot_750.calcExpVar()\n",
    "reg_scot_1000.calcExpVar()\n",
    "reg_scot_5000.calcExpVar()\n",
    "reg_scotlass_1.calcExpVar()\n",
    "reg_scotlass_1pt2.calcExpVar()\n",
    "reg_scotlass_1pt5.calcExpVar()\n",
    "reg_scotlass_1pt6.calcExpVar()\n",
    "reg_scotlass_2.calcExpVar()\n",
    "\n",
    "#reg_reg.plotSparsitytoEV(0)\n",
    "reg_scotlass_1.plotSparsitytoEV(0)\n",
    "reg_scotlass_1pt5.plotSparsitytoEV(0)\n",
    "reg_scotlass_1pt6.plotSparsitytoEV(0)\n",
    "#reg_scotlass_2.plotSparsitytoEV(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(reg_reg.pcs))\n",
    "\n",
    "vm_reg = np.apply_along_axis(varimax, axis = 1, arr = reg_reg.pcs)\n",
    "vm_scot = np.apply_along_axis(varimax, axis = 1, arr = reg_scot.pcs)\n",
    "\n",
    "plt.plot(x, vm_reg, label = \"regular\")\n",
    "plt.plot(x, vm_scot, label = \"SCoT\")\n",
    "plt.xlabel('Number of component')\n",
    "plt.ylabel('Varimax criterion')\n",
    "plt.legend()\n",
    "plt.title(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(reg_scotlass_1pt8.pcs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.apply_along_axis(varimax, axis = 1, arr = reg_scotlass_14.pcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.apply_along_axis(varimax, axis = 1, arr = reg_scot.pcs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_reg_ord = list(reversed(np.argsort(abs(reg_reg.pcs[0]))))+np.ones(len(reg_reg.pcs[0]))\n",
    "\n",
    "reg_scot_500_ord = list(reversed(np.argsort(abs(reg_scot_500.pcs[0]))))+np.ones(len(reg_scot_500.pcs[0]))\n",
    "reg_scot_750_ord = list(reversed(np.argsort(abs(reg_scot_750.pcs[0]))))+np.ones(len(reg_scot_750.pcs[0]))\n",
    "reg_scot_1000_ord = list(reversed(np.argsort(abs(reg_scot_1000.pcs[0]))))+np.ones(len(reg_scot_1000.pcs[0]))\n",
    "reg_scot_5000_ord = list(reversed(np.argsort(abs(reg_scot_5000.pcs[0]))))+np.ones(len(reg_scot_5000.pcs[0]))\n",
    "\n",
    "reg_scotlass_1_ord = list(reversed(np.argsort(abs(reg_scotlass_1.pcs[0]))))+np.ones(len(reg_scotlass_1.pcs[0]))\n",
    "reg_scotlass_1pt2_ord = list(reversed(np.argsort(abs(reg_scotlass_1pt2.pcs[0]))))+np.ones(len(reg_scotlass_1pt2.pcs[0]))\n",
    "reg_scotlass_1pt5_ord = list(reversed(np.argsort(abs(reg_scotlass_1pt5.pcs[0]))))+np.ones(len(reg_scotlass_1pt5.pcs[0]))\n",
    "reg_scotlass_1pt6_ord = list(reversed(np.argsort(abs(reg_scotlass_1pt6.pcs[0]))))+np.ones(len(reg_scotlass_1pt6.pcs[0]))\n",
    "reg_scotlass_2_ord = list(reversed(np.argsort(abs(reg_scotlass_2.pcs[0]))))+np.ones(len(reg_scotlass_2.pcs[0]))\n",
    "\n",
    "ordered_loadings = np.array([reg_reg_ord,\n",
    "                    reg_scot_500_ord,\n",
    "                    reg_scot_750_ord,\n",
    "                    reg_scot_1000_ord,\n",
    "                    reg_scot_5000_ord,\n",
    "                    reg_scotlass_2_ord,\n",
    "                    reg_scotlass_1pt5_ord,\n",
    "                    reg_scotlass_1pt2_ord,\n",
    "                    reg_scotlass_1_ord])\n",
    "\n",
    "gini_coefs = np.array([reg_reg.gini[0],\n",
    "              reg_scot_500.gini[0],    \n",
    "              reg_scot_750.gini[0],             \n",
    "              reg_scot_1000.gini[0],\n",
    "              reg_scot_5000.gini[0],\n",
    "              reg_scotlass_2.gini[0],\n",
    "              reg_scotlass_1pt5.gini[0],                    \n",
    "              reg_scotlass_1pt2.gini[0],\n",
    "              reg_scotlass_1.gini[0]])\n",
    "\n",
    "pevs = np.array([reg_reg.pev[0],\n",
    "              reg_scot_500.pev[0],    \n",
    "              reg_scot_750.pev[0],             \n",
    "              reg_scot_1000.pev[0],\n",
    "              reg_scot_5000.pev[0],\n",
    "              reg_scotlass_2.pev[0],\n",
    "              reg_scotlass_1pt5.pev[0],                    \n",
    "              reg_scotlass_1pt2.pev[0],\n",
    "              reg_scotlass_1.pev[0]])\n",
    "\n",
    "gini_coefs = np.reshape(gini_coefs,(len(gini_coefs),1))\n",
    "\n",
    "pevs = np.reshape(pevs,(len(pevs),1))\n",
    "\n",
    "weighted_gini = gini_coefs * pevs\n",
    "\n",
    "df_data = np.concatenate((gini_coefs, pevs, weighted_gini, ordered_loadings), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = ['PCA',\n",
    "        'SCoT (reg_param = 500)',\n",
    "        'SCoT (reg_param = 750)',\n",
    "        'SCoT (reg_param = 1000)',\n",
    "        'SCoT (reg_param = 5000)',\n",
    "        'SCoTLASS (reg_param = 2)',\n",
    "        'SCoTLASS (reg_param = 1.5)',\n",
    "        'SCoTLASS (reg_param = 1.2)',\n",
    "        'SCoTLASS (reg_param = 1)']\n",
    "\n",
    "cols = ['gini','pev','weighted gini']+['%d' %(i+1) for i in range(X_small.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_load_df = pd.DataFrame(df_data,index = rows, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gini</th>\n",
       "      <th>pev</th>\n",
       "      <th>weighted gini</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCA</th>\n",
       "      <td>0.198764</td>\n",
       "      <td>0.607015</td>\n",
       "      <td>0.120653</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoT (reg_param = 500)</th>\n",
       "      <td>0.265218</td>\n",
       "      <td>0.594486</td>\n",
       "      <td>0.157668</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoT (reg_param = 750)</th>\n",
       "      <td>0.691130</td>\n",
       "      <td>0.169361</td>\n",
       "      <td>0.117050</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoT (reg_param = 1000)</th>\n",
       "      <td>0.741877</td>\n",
       "      <td>0.150669</td>\n",
       "      <td>0.111778</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoT (reg_param = 5000)</th>\n",
       "      <td>0.863084</td>\n",
       "      <td>0.116907</td>\n",
       "      <td>0.100901</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoTLASS (reg_param = 2)</th>\n",
       "      <td>0.265056</td>\n",
       "      <td>0.595580</td>\n",
       "      <td>0.157862</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoTLASS (reg_param = 1.5)</th>\n",
       "      <td>0.265056</td>\n",
       "      <td>0.595580</td>\n",
       "      <td>0.157862</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoTLASS (reg_param = 1.2)</th>\n",
       "      <td>0.833770</td>\n",
       "      <td>0.148805</td>\n",
       "      <td>0.124069</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoTLASS (reg_param = 1)</th>\n",
       "      <td>0.888884</td>\n",
       "      <td>0.111112</td>\n",
       "      <td>0.098766</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                gini       pev  weighted gini    1    2    3  \\\n",
       "PCA                         0.198764  0.607015       0.120653  4.0  7.0  9.0   \n",
       "SCoT (reg_param = 500)      0.265218  0.594486       0.157668  7.0  4.0  9.0   \n",
       "SCoT (reg_param = 750)      0.691130  0.169361       0.117050  7.0  4.0  9.0   \n",
       "SCoT (reg_param = 1000)     0.741877  0.150669       0.111778  7.0  4.0  9.0   \n",
       "SCoT (reg_param = 5000)     0.863084  0.116907       0.100901  7.0  4.0  6.0   \n",
       "SCoTLASS (reg_param = 2)    0.265056  0.595580       0.157862  7.0  4.0  6.0   \n",
       "SCoTLASS (reg_param = 1.5)  0.265056  0.595580       0.157862  7.0  4.0  6.0   \n",
       "SCoTLASS (reg_param = 1.2)  0.833770  0.148805       0.124069  7.0  4.0  6.0   \n",
       "SCoTLASS (reg_param = 1)    0.888884  0.111112       0.098766  7.0  9.0  1.0   \n",
       "\n",
       "                              4    5    6    7    8    9  \n",
       "PCA                         1.0  8.0  6.0  5.0  3.0  2.0  \n",
       "SCoT (reg_param = 500)      1.0  6.0  5.0  8.0  3.0  2.0  \n",
       "SCoT (reg_param = 750)      1.0  6.0  5.0  8.0  3.0  2.0  \n",
       "SCoT (reg_param = 1000)     6.0  1.0  5.0  8.0  3.0  2.0  \n",
       "SCoT (reg_param = 5000)     9.0  1.0  5.0  8.0  3.0  2.0  \n",
       "SCoTLASS (reg_param = 2)    5.0  9.0  1.0  8.0  3.0  2.0  \n",
       "SCoTLASS (reg_param = 1.5)  5.0  9.0  1.0  8.0  3.0  2.0  \n",
       "SCoTLASS (reg_param = 1.2)  9.0  1.0  5.0  8.0  3.0  2.0  \n",
       "SCoTLASS (reg_param = 1)    6.0  4.0  5.0  8.0  3.0  2.0  "
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordered_load_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadings:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var 1</th>\n",
       "      <th>var 2</th>\n",
       "      <th>var 3</th>\n",
       "      <th>var 4</th>\n",
       "      <th>var 5</th>\n",
       "      <th>var 6</th>\n",
       "      <th>var 7</th>\n",
       "      <th>var 8</th>\n",
       "      <th>var 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.39</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.22</td>\n",
       "      <td>0.64</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.52</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var 1  var 2  var 3  var 4  var 5  var 6  var 7  var 8  var 9\n",
       "0   0.34   0.00   0.00   0.41   0.37   0.41   0.43   0.33   0.35\n",
       "1  -0.15   0.69   0.67  -0.05   0.10   0.16   0.04  -0.03  -0.11\n",
       "2   0.71   0.08   0.26  -0.00   0.00  -0.60  -0.15   0.00   0.20\n",
       "3  -0.18   0.09   0.00   0.00  -0.20  -0.00  -0.49   0.79   0.25\n",
       "4  -0.08   0.12  -0.01  -0.00  -0.48   0.17   0.00  -0.39   0.75\n",
       "5   0.22   0.64  -0.67  -0.29   0.10   0.05  -0.00   0.01  -0.03\n",
       "6   0.01  -0.20   0.16  -0.81   0.00  -0.00   0.44   0.25   0.16\n",
       "7   0.00   0.16  -0.06   0.26  -0.65  -0.23   0.55   0.24  -0.27\n",
       "8  -0.52   0.13  -0.11   0.14   0.39  -0.61   0.24   0.01   0.32"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('loadings:')\n",
    "pd.DataFrame([np.around(reg_scotlass_2.pcs[i],2) for i in range(len(reg_scotlass_2.pcs))],columns=['var %d' % i for i in range(1,len(reg_scotlass_2.pcs)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadings:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var 1</th>\n",
       "      <th>var 2</th>\n",
       "      <th>var 3</th>\n",
       "      <th>var 4</th>\n",
       "      <th>var 5</th>\n",
       "      <th>var 6</th>\n",
       "      <th>var 7</th>\n",
       "      <th>var 8</th>\n",
       "      <th>var 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.24</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.59</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.22</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.29</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.31</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.26</td>\n",
       "      <td>-0.57</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.53</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.39</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.28</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.63</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var 1  var 2  var 3  var 4  var 5  var 6  var 7  var 8  var 9\n",
       "0   0.39  -0.05   0.09   0.40   0.35   0.35   0.39   0.36   0.39\n",
       "1  -0.24   0.66   0.59  -0.06   0.17   0.28   0.10  -0.09  -0.18\n",
       "2  -0.22   0.33  -0.48   0.31   0.29  -0.02  -0.31   0.49  -0.32\n",
       "3  -0.13  -0.09  -0.44  -0.34   0.48   0.49   0.11  -0.42  -0.03\n",
       "4  -0.26  -0.57   0.42   0.06   0.53  -0.21  -0.04   0.09  -0.30\n",
       "5   0.08  -0.19   0.22  -0.08  -0.11   0.53  -0.75   0.14   0.16\n",
       "6  -0.39  -0.28  -0.03   0.28  -0.49   0.46   0.34   0.09  -0.33\n",
       "7  -0.00   0.03  -0.01   0.73   0.06  -0.04  -0.23  -0.63   0.06\n",
       "8  -0.71   0.00  -0.02   0.01   0.02  -0.10   0.00   0.09   0.69"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('loadings:')\n",
    "pd.DataFrame([np.around(reg_reg.pcs[i],2) for i in range(len(reg_reg.pcs))],columns=['var %d' % i for i in range(1,len(reg_reg.pcs)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.224363045918498"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.degrees(np.arccos(reg_reg.pcs[0] @ reg_scotlass_2.pcs[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Variable description |\n",
    "| --- | --- |\n",
    "| x1 | I0 - Impedivity (ohm) at zero frequency\n",
    "| x2 | PA500 - phase angle at 500 KHz\n",
    "| x3 | HFS - high-frequency slope of phase angle\n",
    "| x4 | DA - impedance distance between spectral ends\n",
    "| x5 | AREA - area under spectrum\n",
    "| x6 | A/DA - area normalized by DA\n",
    "| x7 | MAX IP - maximum of the spectrum\n",
    "| x8 | DR - distance between I0 and real part of the maximum frequency point\n",
    "| x9 | P - length of the spectral curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loadings:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var 1</th>\n",
       "      <th>var 2</th>\n",
       "      <th>var 3</th>\n",
       "      <th>var 4</th>\n",
       "      <th>var 5</th>\n",
       "      <th>var 6</th>\n",
       "      <th>var 7</th>\n",
       "      <th>var 8</th>\n",
       "      <th>var 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PCA</th>\n",
       "      <td>0.39</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoT (reg_param = 500)</th>\n",
       "      <td>0.35</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoT (reg_param = 1000)</th>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoTLASS (Reg_param = 1)</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCoTLASS (reg_param = 2)</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          var 1  var 2  var 3  var 4  var 5  var 6  var 7  \\\n",
       "PCA                        0.39  -0.05   0.09   0.40   0.35   0.35   0.39   \n",
       "SCoT (reg_param = 500)     0.35  -0.01   0.07   0.44   0.31   0.34   0.49   \n",
       "SCoT (reg_param = 1000)    0.03  -0.00   0.01   0.04   0.03   0.04   1.00   \n",
       "SCoTLASS (Reg_param = 1)   0.00  -0.00   0.00   0.00   0.00   0.00   1.00   \n",
       "SCoTLASS (reg_param = 2)   0.34   0.00   0.00   0.41   0.37   0.41   0.43   \n",
       "\n",
       "                          var 8  var 9  \n",
       "PCA                        0.36   0.39  \n",
       "SCoT (reg_param = 500)     0.30   0.37  \n",
       "SCoT (reg_param = 1000)    0.03   0.04  \n",
       "SCoTLASS (Reg_param = 1)   0.00   0.00  \n",
       "SCoTLASS (reg_param = 2)   0.33   0.35  "
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('loadings:')\n",
    "loading_data = np.around([reg_reg.pcs[0],\n",
    "        reg_scot_500.pcs[0],\n",
    "        reg_scot_1000.pcs[0],\n",
    "        reg_scotlass_1.pcs[0],\n",
    "        reg_scotlass_2.pcs[0]],2)\n",
    "\n",
    "index = [\"PCA\",\"SCoT (reg_param = 500)\",\"SCoT (reg_param = 1000)\",\"SCoTLASS (Reg_param = 1)\",\"SCoTLASS (reg_param = 2)\"]\n",
    "pd.DataFrame(loading_data,index = index, columns=['var %d' % i for i in range(1,len(reg_scotlass_2.pcs)+1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
