{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "data_df = pd.read_csv('../Data/data.csv')\n",
    "labels_df = pd.read_csv('../Data/labels.csv')\n",
    "\n",
    "data = np.array(data_df)[:,1:]#data is n x p matrix\n",
    "labels = np.array(labels_df)\n",
    "\n",
    "data = StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def penalty_1(x):\n",
    "    '''\n",
    "    regularization penalty function for scotlass\n",
    "    \n",
    "    function takes x (float)\n",
    "    \n",
    "    function returns penalty value (float)\n",
    "    '''\n",
    "    penalty = (0.5 * x) * (1 + np.tanh(1000*x))\n",
    "    \n",
    "    return penalty\n",
    "\n",
    "def objective_1(sigma,v,reg_param):\n",
    "    '''\n",
    "    objective function for scotlass\n",
    "    \n",
    "    function takes\n",
    "    - sigma: p x p covariance matrix\n",
    "    - v: array of length p\n",
    "    - reg_param: regularization parameter (positive float)\n",
    "    \n",
    "    function returns\n",
    "    - objective function value at v\n",
    "    '''\n",
    "    v = np.array(v)\n",
    "    obj = ((0.5*v @ sigma) @ v.T) - 1000 * penalty_1(v @ np.tanh((1000*v).T)-reg_param)\n",
    "    \n",
    "    return obj\n",
    "\n",
    "def gradient_1(sigma,v,reg_param):\n",
    "    '''\n",
    "    gradient of objective function for scotlass\n",
    "    \n",
    "    function takes\n",
    "    - sigma: p x p covariance matrix\n",
    "    - v: array of length p\n",
    "    - reg_param: regularization parameter (positive float)\n",
    "    \n",
    "    function returns\n",
    "    - gradient of objective function at v\n",
    "    '''\n",
    "    v = np.array(v)\n",
    "    y = (v @ np.tanh(1000*v))-reg_param\n",
    "    z = np.tanh(1000*v)+(np.diag(np.cosh(y*v))@ (1000*v).T)\n",
    "    grad = (sigma @ v.T) - 0.5*1000*(1+np.tanh((1000*y)+(np.cosh(1000*y)**(-2))*(1000*y)))*np.array(z)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "def scotlass_1(X,max_iter,reg_param):\n",
    "    '''\n",
    "    function takes\n",
    "    - X: n x p scaled and centered dataset\n",
    "    - max_iters: max number of steps (positive integer)\n",
    "    - reg_param: regularization parameter (positive float); reg_param should be <= sqrt(p)\n",
    "    \n",
    "    function returns\n",
    "    - v: first sparse principal direction (array of length p)\n",
    "    - variance of data along v\n",
    "    '''\n",
    "    iters = 1\n",
    "    delta = 0\n",
    "    alpha = 1/iters # decreasing step size\n",
    "    sigma = np.cov(X.T)\n",
    "    v = ([1]*X.shape[1])/np.linalg.norm([1]*X.shape[1]) #initialize v with equal loadings\n",
    "    while iters < max_iter:\n",
    "        v_new = v + alpha*gradient_1(sigma,v,reg_param)\n",
    "        v_proj = v_new/(np.linalg.norm(v_new)) # project loading vector back onto feasible set (vectors of l2 norm of 1)\n",
    "        iters +=1\n",
    "        updated_obj = objective_1(sigma,v_proj,reg_param)\n",
    "        old_obj = objective_1(sigma,v,reg_param)\n",
    "        delta = updated_obj - old_obj\n",
    "        print('delta: '+str(delta))\n",
    "        v = v_proj\n",
    "        \n",
    "    return v, v @ sigma @ v.T # return loadings array v and variance of data along v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta: -0.07352227531373501\n",
      "delta: -0.09909310948569328\n",
      "delta: -0.12030575214885175\n",
      "delta: -0.11089282188913785\n",
      "delta: 0.0013636403891723603\n",
      "delta: 0.40174790724995546\n",
      "delta: 1.5482796417200007\n",
      "delta: 4.548873417137656\n",
      "delta: 12.049193183338502\n",
      "delta: 30.326767680468038\n",
      "delta: 74.29606938816141\n",
      "delta: 179.95247694835416\n",
      "delta: 438.4892616754514\n",
      "delta: 1112.2367537524551\n",
      "delta: 3251.2838724718895\n",
      "delta: 23692.161571119475\n",
      "delta: 104372.04299168136\n",
      "delta: -102317.6555582541\n",
      "delta: 81119.09481600297\n"
     ]
    }
   ],
   "source": [
    "v, v_EV = scotlass_1(data,20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
