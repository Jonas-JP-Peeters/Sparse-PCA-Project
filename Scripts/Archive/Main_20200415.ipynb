{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../Data/data.csv\").drop(['Unnamed: 0'], axis = 1).to_numpy()\n",
    "y = pd.read_csv(\"../Data/labels.csv\").drop(['Unnamed: 0'], axis = 1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_proto = X[1:101, 1:201]\n",
    "y_proto = y[1:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCAObject:\n",
    "    def __init__(self, PCs, X, label):\n",
    "        assert len(PCs) == X.shape[0], \"Need all the principal components!\"\n",
    "        self.pcs = PCs\n",
    "        self.X = StandardScaler().fit_transform(X)\n",
    "        self.cov = np.cov(X.T)\n",
    "        self.label = label\n",
    "    \n",
    "    def calcExpVar(self):\n",
    "        self.ev = np.diag(PCs @ np.cov(X.T) @ PCs.T)\n",
    "        self.pev = [ev/sum(self.ev) for ev in self.ev]\n",
    "        \n",
    "    def calcNonZeroLoads(self):\n",
    "        self.nonZeroLoads = [np.count_nonzero(pc) for pc in self.pcs]\n",
    "        \n",
    "    def plotNonZeroLoadtoPEV(self):\n",
    "        if self.pev == None: self.calcExpVar()\n",
    "        if self.nonZeroLoads == None: self.calcNonZeroLoads()\n",
    "            \n",
    "        plt.plot(self.nonZeroLoads, self.pev, label=self.label)\n",
    "        plt.xlabel('Number of non-zero loadings')\n",
    "        plt.xscale('log')\n",
    "        plt.ylabel('Percentage of explained variance (PEV)')\n",
    "        plt.title('Percentage of explained variance(PEV) vs non-zero loadings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_PCA(X, k = \"all\"): \n",
    "    \"\"\"\n",
    "    function takes an n x p feature matrix\n",
    "    returns two arrays:\n",
    "    - array with percentage of explained variance in first k principal directions (k_comp x 1)\n",
    "    - array with principal directions (k_comp x p)\n",
    "    \"\"\"\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    if k == \"all\": k = min(X.shape[0],X.shape[1])\n",
    "    pca = PCA(n_components = k)\n",
    "    pca.fit(X)\n",
    "    PEVs = pca.explained_variance_ratio_\n",
    "    prin_comp = pca.components_\n",
    "    EVs = pca.explained_variance_\n",
    "    \n",
    "    return PEVs, prin_comp, EVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_PCA(X, thresh = 1e-1, k = \"all\"):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - X: n x p feature matrix\n",
    "    - thresh: float representing this non-zero cutoff\n",
    "    - k: integer for number of principal directions wanted\n",
    "    returns one array:\n",
    "    - array with principal components in its columns (k x p)\n",
    "    \"\"\"\n",
    "    if k == \"all\": k = min(X.shape[0],X.shape[1])\n",
    "\n",
    "    pcs = reg_PCA(X)[1]\n",
    "    pcs = (np.abs(pcs) >= thresh).astype(int) * pcs\n",
    "    \n",
    "    return pcs[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonZeroLoad_PCA(X,j, k = \"max\"):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - X: n x p feature matrix\n",
    "    - j: integer for number of non-zero loadings,\n",
    "    - k: integer for number of principal directions wanted\n",
    "    returns three arrays:\n",
    "    - array with percentages of explained variance in first k principal directions (k x 1)\n",
    "    - array with principal directions (k x p)\n",
    "    - array with explained variances\n",
    "    \"\"\"   \n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    if k == \"all\": k = min(X.shape[0],X.shape[1])\n",
    "    \n",
    "    PCA_PEV, PCA_PC, PCA_EV = reg_PCA(X,min(X.shape[0],X.shape[1]))\n",
    "    \n",
    "    total_var = sum(PCA_EV)\n",
    "    \n",
    "    thresh_PCA_PC = np.empty((0,PCA_PC.shape[1]))\n",
    "    thresh_PCA_PEV = []\n",
    "    thresh_PCA_EV = []\n",
    "    \n",
    "    PCA_PC_sorted = np.sort(np.absolute(PCA_PC), axis = 1)\n",
    "    for m in range(k):\n",
    "        thresh = PCA_PC_sorted[m][-j]\n",
    "        thresh_PC = (np.absolute(PCA_PC[m]) >= thresh).astype(int)*PCA_PC[m]\n",
    "        thresh_PCA_PC = np.vstack((thresh_PCA_PC, thresh_PC))\n",
    "    \n",
    "    return thresh_PCA_PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCs = reg_PCA(X_proto)[1]\n",
    "reg = PCAObject(PCs, X_proto, \"Regular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing target new variance...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.02365623, -0.01519819, -0.04110087, -0.10380788])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r, s = PCs[0], PCs[1]\n",
    "k = 1\n",
    "X_scaled = StandardScaler().fit_transform(X_proto)\n",
    "r_new, s_new, v_r, v_s, v_rs, v_old_r, v_old_s, v_old_rs, beta_star = SimpTrans(r, s, k, X_scaled)\n",
    "r[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.04731247, -0.03039637, -0.08220175, -0.20761577])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_new[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.20772519288774"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_old_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.20772519288774"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimpTrans(r, s, k, X_scaled):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - Two directions r and s to transform\n",
    "    - An integer k that restricts the possible directions\n",
    "    - The scaled data matrix X\n",
    "    returns two vectors and three floats\n",
    "    - Two new directions r and s\n",
    "    - Two floats representing the variances explained by the new directions r and s\n",
    "    - One float representing the covariance of the new directions r and s\n",
    "    \"\"\"\n",
    "    # Calculate the covariance matrix for the two directions\n",
    "    cov = np.vstack((r,s)) @ np.cov(X_scaled.T) @ np.vstack((r,s)).T\n",
    "    v_old_r, v_old_s, v_old_rs = cov[0,0], cov[1,1], cov[0,1]\n",
    "    \n",
    "    # Get a list of all possible betas\n",
    "    poss_beta1 = [i/2**k for i in range(-2**k, 2**k+1, 1)]\n",
    "    poss_beta2 = [2**k/i for i in range(-2**k, 2**k+1, 1) if i != 0]\n",
    "    poss_beta = np.sort(list(set(poss_beta1 + poss_beta2)))\n",
    "    \n",
    "    # Calculate the norms of the two directions\n",
    "    l2_r, l2_s = np.linalg.norm(r)**2, np.linalg.norm(s)**2\n",
    "    \n",
    "    # Define closure function for maximization problem\n",
    "    def newDirVar(beta):\n",
    "        \"\"\"\n",
    "        function takes\n",
    "        - Covariance matrix of directions\n",
    "        - Norms of both directions\n",
    "        - Parameter beta\n",
    "        returns one float\n",
    "        - Float representing the variance in the new direction\n",
    "        \"\"\"\n",
    "        v_r, v_s, v_rs = cov[0,0], cov[1,1], cov[0,1]\n",
    "        nom = l2_r*v_r + 2*beta*np.sqrt(l2_r*l2_s)*v_rs + beta**2*l2_s*v_s\n",
    "        denom = l2_r + beta**2*l2_s\n",
    "        return -nom/denom\n",
    "    \n",
    "    # Optimize the variance of the first new direction r_new\n",
    "    print(\"Optimizing target new variance...\")\n",
    "    beta_star = minimize(newDirVar, 0, method = 'BFGS')\n",
    "    \n",
    "    # Select beta from possible values that's closest to the optimal value\n",
    "    beta_star = min(list(poss_beta), \n",
    "                    key = lambda x:abs(x-beta_star.x))\n",
    "    \n",
    "    # Calculate the two new directions\n",
    "    if abs(beta_star) <= 1:\n",
    "        r_new = 2**k*r + 2**k*beta_star*s\n",
    "        s_new = 2**k*beta_star*l2_s*r - 2**k*l2_r*s\n",
    "    else:\n",
    "        r_new = 2**k*r/beta_star + 2**k*s\n",
    "        s_new = 2**k*l2_s*r - 2**k*l2_r*s/beta_star\n",
    "    \n",
    "    # Calculate variances and covariance of the new directions\n",
    "    P = np.array([[1, l2_s*beta_star],[beta_star, -l2_r]])\n",
    "    cov_new = P.T @ cov @ P\n",
    "    v_r, v_s, v_rs = cov_new[0,0], cov_new[1,1], cov_new[0,1]\n",
    "    \n",
    "    return r_new, s_new, v_r, v_s, v_rs, v_old_r, v_old_s, v_old_rs, beta_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pcPairFinder(cov, cache):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - A covariance matrix\n",
    "    - A cache containing the indices of excluded pcs\n",
    "    returns two integers:\n",
    "    - i_r: the index of the first principal component\n",
    "    - i_s: the index of the second principal component\n",
    "    \"\"\"\n",
    "    # Turn covariance matrix into a sparse lower triangular matrix\n",
    "    grid = np.tril(cov, k = -1)\n",
    "    # Flatten the grid and sort from largest cov to smallest cov\n",
    "    srt = np.sort(np.ravel(grid), kind = 'heapsort')\n",
    "    lst = list(np.flip(np.trim_zeros(srt)))\n",
    "    mask = False\n",
    "    \n",
    "    # Find the pair of pcs that are not already in the cache and hav\n",
    "    # the highest covariance in the grid\n",
    "    while not np.any(mask):\n",
    "        covar = lst.pop(0)\n",
    "        index = np.argwhere(grid == covar)\n",
    "        mask = np.ravel(np.invert(np.any(np.isin(index, cache), axis = 1, keepdims = True)))\n",
    "\n",
    "    # Unpack the indices\n",
    "    i_r, i_s = index[mask,:][0]\n",
    "    return i_r, i_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_PCA(X, k, iters = 2):\n",
    "    \"\"\"\n",
    "    function takes\n",
    "    - An unscaled data matrix X\n",
    "    - An integer k that restricts the possible directions\n",
    "    - An integer indicating the number of iterations\n",
    "    returns one array:\n",
    "    - array with principal components in its columns (k x p)\n",
    "    \"\"\"\n",
    "    # Retrieve the principal components and their covariance matrix\n",
    "    pcs = reg_PCA(X)[1]\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    cov = np.cov(X.T)\n",
    "    \n",
    "    # Setup up globals for loop\n",
    "    cov_pc = pcs @ cov @ pcs.T\n",
    "    cache = []\n",
    "    \n",
    "    for _ in range(iters):\n",
    "        while len(cache) <= len(pcs) - 2:\n",
    "            clear_output(wait = True)\n",
    "            print(\"Working on principal component \", len(cache) + 2,\"/\",len(pcs))\n",
    "            \n",
    "            # Find set of principal components to transform\n",
    "            i_r, i_s = pcPairFinder(cov_pc, cache)\n",
    "            r, s = pcs[i_r], pcs[i_s]\n",
    "            cache += [i_r, i_s]\n",
    "            \n",
    "            # Transform the pair of components\n",
    "            print(\"Determining new directions...\")\n",
    "            r_new, s_new, v_r, v_s, v_rs = SimpTrans(r, s, k, X_scaled)\n",
    "\n",
    "            # Update the principal components\n",
    "            pcs[i_r] = r_new\n",
    "            pcs[i_s] = s_new\n",
    "            \n",
    "            # Update the grid matrix\n",
    "            cov_pc[i_s, i_r], cov_pc[i_r, i_s] = v_rs, v_rs\n",
    "    \n",
    "    return pcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on principal component  100 / 100\n",
      "Determining new directions...\n",
      "Optimizing target new variance...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.04731247,  0.03039637,  0.08220175, ...,  0.06533126,\n",
       "        -0.03597368, -0.00844237],\n",
       "       [ 0.04375186, -0.13096553,  0.04633334, ...,  0.10686803,\n",
       "        -0.16336375,  0.09067011],\n",
       "       [ 0.22685844,  0.17815668,  0.21355734, ...,  0.13263308,\n",
       "        -0.09529372, -0.2212941 ],\n",
       "       ...,\n",
       "       [-0.07052483,  0.16484458,  0.17802846, ...,  0.10711341,\n",
       "         0.0441666 , -0.05536424],\n",
       "       [-0.09819298,  0.14240624, -0.00373368, ...,  0.33874281,\n",
       "        -0.14267526, -0.18931907],\n",
       "       [-0.00327837,  0.07643644,  0.09458163, ...,  0.00288164,\n",
       "         0.01779362, -0.02474867]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_PCA(X_proto, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
